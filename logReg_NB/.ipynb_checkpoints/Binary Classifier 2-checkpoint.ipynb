{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier 2\n",
    "TJ Kim, 21 Oct 2019\n",
    "\n",
    "We build a logistic regression model for the data in encoded_adult.csv. The inputs are all the encoded characteristics, while the output is whether or not the income is greater than 50k or not for a person (binary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "First we import CSV data as pandas and divide to test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Import Dataset\n",
    "filename = \"adult_encoded.csv\"\n",
    "df = pd.read_csv(filename, sep='\\s*,\\s*',engine = 'python')\n",
    "\n",
    "# Separate each dataset into training and testing data\n",
    "total_train,total_test = train_test_split(df, random_state=40, test_size=0.3, shuffle=True)\n",
    "\n",
    "# Separate each sub dataset to input and output\n",
    "total_train_data = total_train.loc[:,total_train.columns != 'income_over_50k']\n",
    "total_train_label = total_train.loc[:,total_train.columns =='income_over_50k']\n",
    "total_test_data = total_train.loc[:,total_test.columns != 'income_over_50k']\n",
    "total_test_label = total_train.loc[:,total_test.columns =='income_over_50k']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Run Logistic Binary Classifier\n",
    "We use pandas to build dataframes and SKlearn's logistic regression based on string based classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkim/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Run Logistic Regression\n",
    "logreg = LogisticRegression(solver=\"liblinear\")\n",
    "logreg.fit(total_train_data,total_train_label)\n",
    "\n",
    "# Predict Test Result and calculate Accuracy\n",
    "y_pred = logreg.predict(total_train_data)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(total_test_data, total_test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Parameter Vector\n",
    "Here we obtain what the parameter vector is so we can solve for it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.30403203e-05, -1.44312943e-02,  5.03137221e-02,\n",
       "         3.09383102e-04,  6.76566732e-04, -4.19043504e-03,\n",
       "        -1.49623969e-01,  5.01265503e-02,  1.34829539e-02,\n",
       "        -4.28483040e-01,  1.00617457e-01, -2.35188858e-02,\n",
       "        -1.16952966e-02, -2.80953837e-01,  9.31203644e-01,\n",
       "        -3.07384610e-02, -8.99961277e-01, -8.94433673e-02,\n",
       "        -7.92009328e-02, -3.22767694e-01, -1.48468597e-01,\n",
       "        -1.72619718e-01, -7.57962444e-02,  3.19681468e-01,\n",
       "        -6.75095317e-02, -1.14746125e-01, -1.22040218e-01,\n",
       "        -2.90428464e-01, -1.65977976e-02,  2.64438922e-01,\n",
       "         1.39764301e-02, -1.22162243e-02,  1.50941845e-02,\n",
       "        -4.18623162e-02, -1.98327115e-02, -9.78331990e-03,\n",
       "        -1.79557204e-01, -1.78689053e-02, -2.22052090e-01,\n",
       "         2.11488232e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear System of Equation Solving Attack\n",
    "\n",
    "Next, we attack the binary logistic classifier we built by inputting d+1 predictions. \"d\" is the number of values in the weight vectors. It is important that we obtain confidence values rather than just binary classifications to make this possible\n",
    "\n",
    "The number of linearly independent equations we need are 40. It will be a challenging and annoying task to ensure that every single equation we use is linearly independent.\n",
    "\n",
    "We can simply take 40 values from the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function - calculate sigmoid inverse given output to sigmoid function, can take 2D vector inputs\n",
    "def get_sigmoid_inv(out_val):\n",
    "    idx = 0\n",
    "    for i in out_val:\n",
    "        if i == 1:\n",
    "            out_val[idx] = 0.999999999999999\n",
    "        idx += 1\n",
    "    in_val = -1*np.log(np.divide(1,out_val) - 1)\n",
    "    return in_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkim/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.81930155e-01, -1.30403203e-05, -1.44312943e-02,  5.03137221e-02,\n",
       "        3.09383102e-04,  6.76566732e-04, -4.19043504e-03, -1.40152760e-01,\n",
       "        8.19935210e-02,  4.53499246e-02, -3.96616070e-01,  0.00000000e+00,\n",
       "        8.34808485e-03,  5.27355937e-16, -2.72951015e-01,  9.39206466e-01,\n",
       "       -2.27356391e-02, -8.91958455e-01, -8.14405453e-02, -7.11981108e-02,\n",
       "       -3.22767694e-01, -1.40152760e-01, -1.86699642e-01, -8.98761681e-02,\n",
       "        3.05601545e-01, -8.15894553e-02, -1.28826049e-01, -6.93889390e-18,\n",
       "       -3.04508388e-01,  0.00000000e+00,  2.50358999e-01, -1.03493595e-04,\n",
       "       -2.62961480e-02,  1.01426080e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.73726480e-03, -1.72511149e-01, -1.08228502e-02, -2.15006035e-01,\n",
       "        2.11488232e-01])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a appropriate number of samples from database to attack with\n",
    "num_queries = logreg.coef_.size + 10\n",
    "attack_sample = df.sample(num_queries)\n",
    "\n",
    "# Divide data and labels\n",
    "sample_x = attack_sample.loc[:,attack_sample.columns != 'income_over_50k']\n",
    "sample_y = attack_sample.loc[:,attack_sample.columns =='income_over_50k']\n",
    "\n",
    "# Obtain P(y = 1) vals for entire array - the confidence intervals for iris setosa (0) vs iris versicolor (1)\n",
    "conf = logreg.predict_proba(sample_x)[:,1]\n",
    "xw_s = get_sigmoid_inv(conf)\n",
    "bias = np.ones((num_queries,1))\n",
    "x_testvals = np.concatenate((bias, sample_x.values), 1)\n",
    "\n",
    "w_approx = np.linalg.lstsq(x_testvals,xw_s)\n",
    "w_approx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.49094231e-01, -1.30403203e-05, -1.44312943e-02,  5.03137221e-02,\n",
       "        3.09383102e-04,  6.76566732e-04, -4.19043504e-03, -1.49623969e-01,\n",
       "        5.01265503e-02,  1.34829539e-02, -4.28483040e-01,  1.00617457e-01,\n",
       "       -2.35188858e-02, -1.16952966e-02, -2.80953837e-01,  9.31203644e-01,\n",
       "       -3.07384610e-02, -8.99961277e-01, -8.94433673e-02, -7.92009328e-02,\n",
       "       -3.22767694e-01, -1.48468597e-01, -1.72619718e-01, -7.57962444e-02,\n",
       "        3.19681468e-01, -6.75095317e-02, -1.14746125e-01, -1.22040218e-01,\n",
       "       -2.90428464e-01, -1.65977976e-02,  2.64438922e-01,  1.39764301e-02,\n",
       "       -1.22162243e-02,  1.50941845e-02, -4.18623162e-02, -1.98327115e-02,\n",
       "       -9.78331990e-03, -1.79557204e-01, -1.78689053e-02, -2.22052090e-01,\n",
       "        2.11488232e-01])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_weights = np.append(logreg.intercept_,logreg.coef_)\n",
    "real_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
