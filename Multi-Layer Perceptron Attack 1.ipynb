{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron Attack\n",
    "TJ Kim, 12 Nov 2019\n",
    "\n",
    "We build a multi-layer perceptron model to classify adult.csv data. Then we perform an equation solving attack. Then, a uniform query attack will be performed, as well as an adaptive retraining attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "First we import CSV data as pandas and divide to test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Import Dataset\n",
    "filename = \"adult_encoded.csv\"\n",
    "df = pd.read_csv(filename, sep='\\s*,\\s*',engine = 'python')\n",
    "df = df.loc[:,df.columns != 'Unnamed: 0']\n",
    "\n",
    "# Separate each dataset into training, testing, and query data\n",
    "total_rest,total_test = train_test_split(df, random_state=30, test_size=0.2, shuffle=True)\n",
    "total_train,queries = train_test_split(total_rest,random_state = 30, test_size = 0.4, shuffle = True)\n",
    "\n",
    "# Separate each sub dataset to input and output\n",
    "total_train_data = total_train.loc[:,total_train.columns != 'income_over_50k']\n",
    "total_train_label = total_train.loc[:,total_train.columns =='income_over_50k']\n",
    "total_test_data = total_train.loc[:,total_test.columns != 'income_over_50k']\n",
    "total_test_label = total_train.loc[:,total_test.columns =='income_over_50k']\n",
    "query_data = queries.loc[:,queries.columns !='income_over_50k']\n",
    "query_label = queries.loc[:,queries.columns =='income_over_50k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23443, 39)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Run MultiLayer Perceptron\n",
    "To have easy access to the weight vectors associated with every layer, we will use pytorch.\n",
    "Our perceptron will have an input layer, a dense layer, and ELU layer, another dense layer, and a loss layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "axes_max = total_train_data.values.max(axis=0)\n",
    "\n",
    "X = torch.from_numpy(total_train_data.values/axes_max).float()\n",
    "y = torch.from_numpy(total_train_label.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        # parameters\n",
    "        # TODO: parameters can be parameterized instead of declaring them here\n",
    "        self.inputSize = 39\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 200\n",
    "        \n",
    "        # weights\n",
    "        \n",
    "        mu1, sigma1 = 0, math.sqrt(2.0/(self.inputSize+self.hiddenSize))\n",
    "        mu2, sigma2 = 0,math.sqrt(2.0/(self.outputSize+self.hiddenSize))\n",
    "        \n",
    "        self.W1 = torch.from_numpy(np.random.normal(mu1,sigma1,[self.inputSize,self.hiddenSize])).float()\n",
    "        self.W2 = torch.from_numpy(np.random.normal(mu2,sigma2,[self.hiddenSize,self.outputSize])).float()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        alpha = 0.9\n",
    "        self.z1 = torch.matmul(X, self.W1) # 3 X 3 \".dot\" does not broadcast in PyTorch\n",
    "        self.z2 = self.ELU(self.z1,alpha) # activation function\n",
    "        self.z3 = torch.matmul(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3) # final activation function\n",
    "        return o\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        # derivative of sigmoid\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def ELU(self,s,alpha):\n",
    "        temp_out = s.clone()\n",
    "        \n",
    "        temp_out[temp_out<=0] = alpha*(np.exp(temp_out[temp_out<=0]-1))\n",
    "        \n",
    "        return temp_out\n",
    "    \n",
    "    def ELUPrime(self,s,alpha):\n",
    "\n",
    "        temp_out2 = torch.from_numpy(np.ones(s.shape)).float()\n",
    "        temp_out2[s<=0] = alpha * torch.exp(s[s<=0])\n",
    "\n",
    "        return temp_out2\n",
    "        \n",
    "    def backward(self, X, y, o):\n",
    "        lr_rate = 0.01\n",
    "        alpha = 0.9\n",
    "        self.o_error = y - o # error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # derivative of sig to error\n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "        self.z2_delta = self.z2_error * self.ELUPrime(self.z2,alpha)\n",
    "        self.W1 += lr_rate * torch.matmul(torch.t(X), self.z2_delta)\n",
    "        self.W2 += lr_rate * torch.matmul(torch.t(self.z2), self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # forward + backward pass for training\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "    def saveWeights(self, model):\n",
    "        # we will use the PyTorch internal storage functions\n",
    "        torch.save(model, \"NN\")\n",
    "        # you can reload model with all the weights and so forth with:\n",
    "        # torch.load(\"NN\")\n",
    "        \n",
    "    def predict(self,X_query, mute):\n",
    "        \n",
    "        if mute is False:\n",
    "            print (\"Predicted data based on trained weights: \")\n",
    "            print (\"Input: \\n\" + str(X_query))\n",
    "            print (\"Output: \\n\" + str(round(self.forward(X_query).numpy()[0])))\n",
    "            print (\"Confidence: \\n\" + str(self.forward(X_query).numpy()[0]))\n",
    "        \n",
    "        prediction = np.around(self.forward(X_query).numpy())\n",
    "        conf = self.forward(X_query).numpy()\n",
    "\n",
    "        return prediction, conf\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build instance of model we just built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.27176985144615173\n",
      "true: \n",
      " tensor([1.])\n",
      "Predicted data based on trained weights: \n",
      "Input: \n",
      "tensor([0.5333, 0.5625, 0.0000, 0.0000, 0.4040, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 1.0000, 1.0000])\n",
      "Output: \n",
      "0.0\n",
      "Confidence: \n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.], dtype=float32), array([0.], dtype=float32))"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 3\n",
    "NN = Neural_Network()\n",
    "for i in range(1):  # trains the NN 1,000 times\n",
    "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))  # mean sum squared loss\n",
    "    NN.train(X, y)\n",
    "NN.saveWeights(NN)\n",
    "print(\"true: \\n\",y[j])\n",
    "NN.predict(X[j,:],False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test NN model on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7617625730495243"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_test = torch.from_numpy(total_test_data.values/axes_max).float()\n",
    "y_test = torch.from_numpy(total_test_label.values).float()\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "confs = np.zeros(X_test.shape[0])\n",
    "mute = True;\n",
    "\n",
    "\n",
    "preds, confs = NN.predict(X_test,mute)\n",
    "    \n",
    "acc = accuracy_score(total_test_label,preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23443"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
